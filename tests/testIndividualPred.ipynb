{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from mrsc.src.model.SVDmodel import SVDmodel\n",
    "from mrsc.src.model.Target import Target\n",
    "from mrsc.src.model.Donor import Donor\n",
    "from mrsc.src.synthcontrol.mRSC import mRSC\n",
    "from mrsc.src.importData import *\n",
    "import mrsc.src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getActivePlayers(stats, year, buffer):\n",
    "    # list of name of the players who were active in this and last year\n",
    "    thisYear = stats[stats.Year == year].copy()\n",
    "    players = list(thisYear.Player.unique())\n",
    "    for i in range(1, buffer+1):\n",
    "        previousYear = stats[stats.Year == (year-i)].copy()\n",
    "        players = list(set(players) & set(previousYear.Player.unique()))\n",
    "    return players\n",
    "\n",
    "def topPlayers(stats, year, metric, n):\n",
    "    stats = stats[stats.Year == year]\n",
    "    stats = stats.groupby('Player').mean().reset_index()\n",
    "    stats_sorted = stats[stats.Year == year].sort_values(metric, ascending = False).reset_index(drop=True)\n",
    "    return stats_sorted[[\"Player\",\"player_id\"]][:n]\n",
    "\n",
    "def removeDuplicated(players, stats):\n",
    "    \"\"\"\n",
    "    players: \"../data/nba-players-stats/player_data.csv\"\n",
    "    stats: \"../data/nba-players-stats/Seasons_Stats.csv\"\n",
    "    \"\"\"\n",
    "    # players with the same name\n",
    "    names = players.name.unique()\n",
    "    duplicated = np.array([])\n",
    "\n",
    "    for name in names:\n",
    "        numrows = len(players[players.name == name])\n",
    "        if numrows != 1:\n",
    "            duplicated = np.append(duplicated, name)\n",
    "\n",
    "    duplicated = np.sort(duplicated)\n",
    "\n",
    "    start_year = players.copy()\n",
    "    start_year = start_year.rename(columns={\"name\":\"Player\"})\n",
    "\n",
    "    # for non-duplicated players\n",
    "    stats_not_duplicated = stats[~stats.Player.isin(duplicated)]\n",
    "    stats_not_duplicated = pd.merge(stats_not_duplicated, start_year, on=\"Player\", how=\"left\")\n",
    "\n",
    "    # only take the values that make sense\n",
    "    stats_not_duplicated = stats_not_duplicated[(stats_not_duplicated.Year >= stats_not_duplicated.year_start) & (stats_not_duplicated.Year <= stats_not_duplicated.year_end )]\n",
    "    stats_not_duplicated[\"year_count\"] = stats_not_duplicated.Year - stats_not_duplicated.year_start\n",
    "\n",
    "    return stats_not_duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import data\n",
    "\"\"\"\n",
    "players = pd.read_csv(\"../data/nba-players-stats/player_data.csv\")\n",
    "players = players[players.year_start >= 1980] # only choose players who started after 1980\n",
    "players[\"player_id\"] = range(0,len(players.name)) # assign id\n",
    "\n",
    "stats = pd.read_csv(\"../data/nba-players-stats/Seasons_Stats.csv\")\n",
    "stats = stats[stats.Player.isin(players.name)]\n",
    "\n",
    "# only after 1980\n",
    "stats = stats[stats.Year >= 1980]\n",
    "\n",
    "# without duplicated names --> to do: how to distinguish multiple player with the same name\n",
    "stats = removeDuplicated(players, stats)\n",
    "stats.Year = stats.Year.astype(int)\n",
    "stats.year_count = stats.year_count.astype(int)\n",
    "\n",
    "# transform stats to a dictionary composed of df's for each stat\n",
    "# the stats are re-calculated to get one stat for each year\n",
    "\n",
    "metricsPerGameColNames = [\"PTS\",\"AST\",\"TOV\",\"TRB\",\"STL\",\"BLK\"]\n",
    "metricsPerGameDict = getMetricsPerGameDict(stats, metricsPerGameColNames)\n",
    "\n",
    "metricsPerCentColNames = [\"FG\",\"FT\",\"3P\"]\n",
    "metricsPerCentDict = getMetricsPerCentDict(stats, metricsPerCentColNames)\n",
    "\n",
    "metricsWeightedColNames = [\"PER\"]\n",
    "metricsWeightedDict = getMetricsWeightedDict(stats, metricsWeightedColNames)\n",
    "\n",
    "allMetricsDict = {**metricsPerGameDict, **metricsPerCentDict, **metricsWeightedDict}\n",
    "allPivotedTableDict = getPivotedTableDict(allMetricsDict)\n",
    "\n",
    "# this matrix will be used to mask the table\n",
    "df_year = pd.pivot_table(stats, values=\"Year\", index=\"Player\", columns = \"year_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# targets to test\n",
    "activePlayers = getActivePlayers(stats, 2016, 4)\n",
    "activePlayers.sort()\n",
    "# to few donors\n",
    "activePlayers.remove(\"Kevin Garnett\")\n",
    "activePlayers.remove(\"Kobe Bryant\")\n",
    "# weird beta behavior\n",
    "activePlayers.remove(\"Jamal Crawford\")\n",
    "activePlayers.remove(\"Mike Miller\")\n",
    "\n",
    "# overall setup\n",
    "expSetup = [\"sliding\", \"SVD\", \"all\", \"pinv\", False]\n",
    "threshold = 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Performance (we want at least better than this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute the error for mean prediction\n",
      "PTS_G    0.618013\n",
      "AST_G    1.272938\n",
      "TOV_G    0.790195\n",
      "PER_w    0.305318\n",
      "FG%      0.107557\n",
      "FT%      0.147169\n",
      "3P%      0.390415\n",
      "TRB_G    0.515323\n",
      "STL_G    0.670241\n",
      "BLK_G    1.446932\n",
      "dtype: float64\n",
      "MAPE for all:  0.64264173902046\n",
      "PTS_G    6.400733\n",
      "AST_G    2.138599\n",
      "TOV_G    0.855015\n",
      "PER_w    5.262524\n",
      "FG%      0.074946\n",
      "FT%      0.136692\n",
      "3P%      0.175561\n",
      "TRB_G    2.526368\n",
      "STL_G    0.477519\n",
      "BLK_G    0.427495\n",
      "dtype: float64\n",
      "RMSE for all:  1.8475451612551297\n"
     ]
    }
   ],
   "source": [
    "metrics_to_use= [\"PTS_G\",\"AST_G\",\"TOV_G\",\"PER_w\", \"FG%\",\"FT%\",\"3P%\",\"TRB_G\",\"STL_G\",\"BLK_G\"]\n",
    "weights = [1.] * 10\n",
    "\n",
    "means = pd.DataFrame([7.9220039916884835,1.7957411223657396, 1.2177917024718974, 12.461764871776813, \n",
    "                      0.43785559339244096, 0.69908195642175319, 0.21029194254679157, 3.4789347250141578, \n",
    "                      0.65261301463080668, 0.40023620475586968], index = metrics_to_use)\n",
    "\n",
    "print(\"compute the error for mean prediction\")\n",
    "pred_all = pd.DataFrame()\n",
    "true_all = pd.DataFrame()\n",
    "for playerName in activePlayers:\n",
    "    target = Target(playerName, allPivotedTableDict, df_year)\n",
    "    donor = Donor(allPivotedTableDict, df_year)\n",
    "\n",
    "    mrsc = mRSC(donor, target, probObservation=1)\n",
    "    mrsc.fit_threshold(metrics_to_use, weights, 2016, pred_length = 1, threshold = threshold, setup = expSetup)\n",
    "\n",
    "    pred = means\n",
    "    true = mrsc.getTrue()\n",
    "    pred.columns = [playerName]\n",
    "    true.columns = [playerName]\n",
    "\n",
    "    pred_all = pd.concat([pred_all, pred], axis=1)\n",
    "    true_all = pd.concat([true_all, true], axis=1)\n",
    "\n",
    "###################\n",
    "mask = (true_all !=0 )\n",
    "mape = np.abs(pred_all - true_all) / true_all[mask]\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "rmse = utils.rmse_2d(true_all, pred_all)\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off vs. Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start experiment - off/def with var-standardized weights\n",
      "PTS_G    0.441639\n",
      "AST_G    0.488677\n",
      "TOV_G    0.375900\n",
      "PER_w    0.263511\n",
      "FG%      0.131360\n",
      "FT%      0.100613\n",
      "3P%      0.270641\n",
      "TRB_G    0.314842\n",
      "STL_G    0.384051\n",
      "BLK_G    0.588030\n",
      "dtype: float64\n",
      "MAPE for all:  0.3453567203167574\n",
      "PTS_G    4.417351\n",
      "AST_G    1.013456\n",
      "TOV_G    0.480871\n",
      "PER_w    4.224764\n",
      "FG%      0.089354\n",
      "FT%      0.112717\n",
      "3P%      0.147596\n",
      "TRB_G    1.461689\n",
      "STL_G    0.278296\n",
      "BLK_G    0.226756\n",
      "dtype: float64\n",
      "RMSE for all:  1.2452850431044076\n"
     ]
    }
   ],
   "source": [
    "offMetrics = [\"PTS_G\",\"AST_G\",\"TOV_G\",\"PER_w\", \"FG%\",\"FT%\",\"3P%\"]\n",
    "defMetrics = [\"TRB_G\",\"STL_G\",\"BLK_G\"]\n",
    "weightsOff = [0.030226243506617984, 0.23767435579974203, 0.62302081521153241, 0.028496590283710845, 0.99135485530619705, 0.96678243679381637, 0.96723382349958986]\n",
    "weightsDef = [0.14231010741961231, 0.82630141067410789, 0.8168122805751753]\n",
    "    \n",
    "print(\"start experiment - off/def with var-standardized weights\")\n",
    "pred_all = pd.DataFrame()\n",
    "true_all = pd.DataFrame()\n",
    "for playerName in activePlayers:\n",
    "    target = Target(playerName, allPivotedTableDict, df_year)\n",
    "    donor = Donor(allPivotedTableDict, df_year)\n",
    "\n",
    "    mrsc = mRSC(donor, target, probObservation=1)\n",
    "    mrsc.fit_threshold(offMetrics, weightsOff, 2016, pred_length = 1, threshold = threshold, setup = expSetup)\n",
    "\n",
    "    predOff = mrsc.predict()\n",
    "    trueOff = mrsc.getTrue()\n",
    "    predOff.columns = [playerName]\n",
    "    trueOff.columns = [playerName]\n",
    "\n",
    "    mrsc.fit_threshold(defMetrics, weightsDef, 2016, pred_length = 1, threshold = threshold, setup = expSetup)\n",
    "    predDef = mrsc.predict()\n",
    "    trueDef = mrsc.getTrue()\n",
    "    predDef.columns = [playerName]\n",
    "    trueDef.columns = [playerName]\n",
    "\n",
    "    pred = pd.concat([predOff, predDef], axis=0)\n",
    "    true = pd.concat([trueOff, trueDef], axis=0)\n",
    "\n",
    "    pred_all = pd.concat([pred_all, pred], axis=1)\n",
    "    true_all = pd.concat([true_all, true], axis=1)\n",
    "\n",
    "###################\n",
    "mask = (true_all !=0 )\n",
    "mape = np.abs(pred_all - true_all) / true_all[mask]\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "rmse = utils.rmse_2d(true_all, pred_all)\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PTS_G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST_G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOV_G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRB_G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STL_G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLK_G</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [PTS_G, AST_G, TOV_G, PER_w, FG%, FT%, 3P%, TRB_G, STL_G, BLK_G]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape.T[mape.T.PTS_G > 100].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start experiment\n",
      "\n",
      "[1.0, 1.0]\n",
      "PTS_G    0.326406\n",
      "PER_w    0.227708\n",
      "dtype: float64\n",
      "MAPE for all:  0.28439772542183495\n",
      "PTS_G    3.251259\n",
      "PER_w    3.301353\n",
      "dtype: float64\n",
      "RMSE for all:  3.2763061215056464\n",
      "\n",
      "[0.03116834550763001, 0.029332465536104278]\n",
      "PTS_G    0.323816\n",
      "PER_w    0.227367\n",
      "dtype: float64\n",
      "MAPE for all:  0.282924819277604\n",
      "PTS_G    3.242725\n",
      "PER_w    3.297933\n",
      "dtype: float64\n",
      "RMSE for all:  3.270329080954553\n"
     ]
    }
   ],
   "source": [
    "metrics_to_use= [\"PTS_G\",\"PER_w\"]\n",
    "\n",
    "weights1 = [1.,1.]\n",
    "weights2 = [0.031168345507630011, 0.029332465536104278]\n",
    "weights_list = [weights1, weights2]\n",
    "\n",
    "print(\"start experiment\")\n",
    "for weights in weights_list:\n",
    "    print()\n",
    "    print(weights)\n",
    "    pred_all = pd.DataFrame()\n",
    "    true_all = pd.DataFrame()\n",
    "    for playerName in activePlayers:\n",
    "        target = Target(playerName, allPivotedTableDict, df_year)\n",
    "        donor = Donor(allPivotedTableDict, df_year)\n",
    "\n",
    "        mrsc = mRSC(donor, target, probObservation=1)\n",
    "        mrsc.fit_threshold(metrics_to_use, weights, 2016, pred_length = 1, threshold = threshold, setup = expSetup)\n",
    "\n",
    "        pred = mrsc.predict()\n",
    "        true = mrsc.getTrue()\n",
    "        pred.columns = [playerName]\n",
    "        true.columns = [playerName]\n",
    "\n",
    "        pred_all = pd.concat([pred_all, pred], axis=1)\n",
    "        true_all = pd.concat([true_all, true], axis=1)\n",
    "\n",
    "    ###################\n",
    "    mask = (true_all !=0 )\n",
    "    mape = np.abs(pred_all - true_all) / true_all[mask]\n",
    "    print(mape.mean(axis=1))\n",
    "    print(\"MAPE for all: \", mape.mean().mean())\n",
    "    rmse = utils.rmse_2d(true_all, pred_all)\n",
    "    print(rmse)\n",
    "    print(\"RMSE for all: \", rmse.mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start experiment\n",
      "AST_G    0.561490\n",
      "TOV_G    0.446343\n",
      "FG%      0.249764\n",
      "FT%      0.257253\n",
      "3P%      0.405253\n",
      "dtype: float64\n",
      "MAPE for all:  0.383793410476059\n",
      "AST_G    1.218134\n",
      "TOV_G    0.544744\n",
      "FG%      0.150243\n",
      "FT%      0.244952\n",
      "3P%      0.177820\n",
      "dtype: float64\n",
      "RMSE for all:  0.4671785601786508\n"
     ]
    }
   ],
   "source": [
    "metrics_to_use= [\"AST_G\",\"TOV_G\", \"FG%\",\"FT%\",\"3P%\"]\n",
    "weights1 = [1.,1.,1.,1.,1.]\n",
    "weights2 = [0.23767435579974203, 0.62302081521153241, 0.99135485530619705, 0.96678243679381637, 0.96723382349958986]\n",
    "\n",
    "\n",
    "print(\"start experiment\")\n",
    "pred_all = pd.DataFrame()\n",
    "true_all = pd.DataFrame()\n",
    "for playerName in activePlayers:\n",
    "    target = Target(playerName, allPivotedTableDict, df_year)\n",
    "    donor = Donor(allPivotedTableDict, df_year)\n",
    "\n",
    "    mrsc = mRSC(donor, target, probObservation=1)\n",
    "    mrsc.fit_threshold(metrics_to_use, weights, 2016, pred_length = 1, threshold = threshold, setup = expSetup)\n",
    "\n",
    "    pred = mrsc.predict()\n",
    "    true = mrsc.getTrue()\n",
    "    pred.columns = [playerName]\n",
    "    true.columns = [playerName]\n",
    "\n",
    "    pred_all = pd.concat([pred_all, pred], axis=1)\n",
    "    true_all = pd.concat([true_all, true], axis=1)\n",
    "\n",
    "###################\n",
    "mask = (true_all !=0 )\n",
    "mape = np.abs(pred_all - true_all) / true_all[mask]\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "rmse = utils.rmse_2d(true_all, pred_all)\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==0.24.2\n",
      "numpy==1.13.3\n",
      "matplotlib==2.1.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to had\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.811166011565746e-16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donor_pre_ok = pd.read_pickle(\"donor_pre_ok\")\n",
    "donor_pre_not_ok = pd.read_pickle(\"donor_pre_not_ok\")\n",
    "utils.rmse_2d(donor_pre_ok, donor_pre_not_ok).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player\n",
       "Brandon Knight    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pre_ok = pd.read_pickle(\"target_pre_ok\")\n",
    "target_pre_not_ok = pd.read_pickle(\"target_pre_not_ok\")\n",
    "utils.rmse_2d(target_pre_ok, target_pre_not_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brandon Knight</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0     1     2     3     5     6     7     8     10    11  \\\n",
       "Player                                                                       \n",
       "Brandon Knight  True  True  True  True  True  True  True  True  True  True   \n",
       "\n",
       "                ...    22    23    25    26    27    28    30    31    32  \\\n",
       "Player          ...                                                         \n",
       "Brandon Knight  ...  True  True  True  True  True  True  True  True  True   \n",
       "\n",
       "                  33  \n",
       "Player                \n",
       "Brandon Knight  True  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_pre_ok == target_pre_not_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_ok = np.linalg.pinv(donor_pre_ok.T).dot(target_pre_ok.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.21083607e-04],\n",
       "       [ -7.99215763e-05],\n",
       "       [ -6.41249914e-05],\n",
       "       ..., \n",
       "       [ -9.38451703e-05],\n",
       "       [ -1.35922110e-04],\n",
       "       [ -2.06877420e-04]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_not_ok = np.linalg.pinv(donor_pre_not_ok.T).dot(target_pre_ok.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.21083607e-04],\n",
       "       [ -7.99215763e-05],\n",
       "       [ -6.41249914e-05],\n",
       "       ..., \n",
       "       [ -9.38451703e-05],\n",
       "       [ -1.35922110e-04],\n",
       "       [ -2.06877420e-04]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_not_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8720890755282711e-19"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.rmse_2d(beta_ok, beta_not_ok).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
