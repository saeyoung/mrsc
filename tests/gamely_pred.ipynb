{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from mrsc.src.model.SVDmodel import SVDmodel\n",
    "from mrsc.src.model.Target import Target\n",
    "from mrsc.src.model.Donor import Donor\n",
    "from mrsc.src.synthcontrol.mRSC import mRSC\n",
    "from mrsc.src.importData import *\n",
    "import mrsc.src.utils as utils\n",
    "\n",
    "from itertools import combinations, product\n",
    "\n",
    "def prepareData(stats):\n",
    "    # transform stats to a dictionary composed of df's for each stat\n",
    "    # the stats are re-calculated to get one stat for each year\n",
    "    metricsPerGameColNames = [\"PTS\",\"AST\",\"TOV\",\"TRB\",\"STL\",\"BLK\",\"3P\"]\n",
    "    metricsPerGameDict = getMetricsPerGameDict(stats, metricsPerGameColNames)\n",
    "\n",
    "    metricsPerCentColNames = [\"FG\",\"FT\"]\n",
    "    metricsPerCentDict = getMetricsPerCentDict(stats, metricsPerCentColNames)\n",
    "\n",
    "    metricsWeightedColNames = [\"PER\"]\n",
    "    metricsWeightedDict = getMetricsWeightedDict(stats, metricsWeightedColNames)\n",
    "\n",
    "    allMetricsDict = {**metricsPerGameDict, **metricsPerCentDict, **metricsWeightedDict}\n",
    "    allPivotedTableDict = getPivotedTableDict(allMetricsDict)\n",
    "    allMetrics = list(allMetricsDict.keys())\n",
    "    return allPivotedTableDict, allMetrics\n",
    "\n",
    "def getActivePlayers(stats, year, buffer):\n",
    "    # list of name of the players who were active in this and last year\n",
    "    thisYear = stats[stats.Year == year].copy()\n",
    "    players = list(thisYear.Player.unique())\n",
    "    for i in range(1, buffer+1):\n",
    "        previousYear = stats[stats.Year == (year-i)].copy()\n",
    "        players = list(set(players) & set(previousYear.Player.unique()))\n",
    "    return players\n",
    "\n",
    "def getTopPlayers(stats, year, metric, n):\n",
    "    stats = stats[stats.Year == year]\n",
    "    stats = stats.groupby('Player').mean().reset_index()\n",
    "    stats_sorted = stats[stats.Year == year].sort_values(metric, ascending = False).reset_index(drop=True)\n",
    "    return stats_sorted[[\"Player\"]][:n]\n",
    "\n",
    "def getBenchmark(target, metrics_to_use, pred_interval):    \n",
    "    target_data, nanIndex = target.concat(metrics_to_use)\n",
    "    num_k = len(metrics_to_use)\n",
    "    interv_index = int(target_data.shape[1]/num_k - pred_interval)\n",
    "    total_index = int(interv_index + 1)\n",
    "    \n",
    "    # true\n",
    "    true = utils.get_postint_data(target_data, interv_index, total_index, num_k).T\n",
    "    true.index = metrics_to_use\n",
    "    \n",
    "    # predictions\n",
    "    history = utils.get_preint_data(target_data, interv_index, total_index, num_k)\n",
    "    pred = []\n",
    "    for i in range(num_k):\n",
    "        pred.append(history.iloc[:,i*interv_index:(i+1)*interv_index].mean(axis=1).to_list())\n",
    "\n",
    "    pred = pd.DataFrame(pred, index=metrics_to_use, columns = [playerName])\n",
    "    return true, pred\n",
    "\n",
    "def getR2(true, pred, bench):\n",
    "    ss_res = pd.DataFrame((true.values - pred.values)**2, index=true.index).sum(axis=1)\n",
    "    ss_tot = pd.DataFrame((true.values - bench.values)**2, index=true.index).sum(axis=1)\n",
    "    return (1-ss_res/ss_tot).to_frame(name = pred.columns.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictionaryGameByGame(data, metrics):\n",
    "    my_dict = {}\n",
    "    for i in range(len(metrics)):\n",
    "        data_pivot = pd.pivot_table(data, values=metrics[i], index=\"playDispNm\", columns = \"gmDate\")\n",
    "        shifted_df = data_pivot.apply(lambda x: pd.Series(x.dropna().values), axis=1).fillna(np.nan)\n",
    "        my_dict.update({metrics[i]: shifted_df})\n",
    "    return my_dict\n",
    "\n",
    "def getMonthlyData(data, metrics):\n",
    "    df = copy.deepcopy(data)\n",
    "    df.index = df.date\n",
    "    df_grouped = df.groupby(by =[df.playDispNm,pd.Grouper(freq='M')]).mean()\n",
    "    \n",
    "    my_dict = {}\n",
    "    for i in range(len(metrics)):\n",
    "        df_pivoted = pd.pivot_table(df_grouped, values = 'playPTS', index='playDispNm', columns=\"date\")\n",
    "        cols = df_pivoted.columns\n",
    "        df_pivoted.columns = range(df_pivoted.shape[1])\n",
    "        my_dict.update({metrics[i]: df_pivoted})\n",
    "    return my_dict, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game by Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** importing data ***\n",
      "*** preparing data ***\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import data\n",
    "\"\"\"\n",
    "print(\"*** importing data ***\")\n",
    "data = pd.read_csv(\"../data/nba-enhanced-stats/2012-18_playerBoxScore.csv\")\n",
    "\n",
    "# metrics = ['playPTS', 'playAST', 'playTO', 'playSTL', 'playBLK',\n",
    "#        'playPF', 'playFGA', 'playFGM', 'playFG%', 'play2PA', 'play2PM',\n",
    "#        'play2P%', 'play3PA', 'play3PM', 'play3P%', 'playFTA', 'playFTM',\n",
    "#        'playFT%', 'playORB', 'playDRB', 'playTRB']\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "\n",
    "date_col = pd.to_datetime(data.gmDate + \" \" + data.gmTime, format='%Y-%m-%d %H:%M').rename(\"date\")\n",
    "data = pd.concat([date_col,data], axis=1)\n",
    "\n",
    "# data_dict = {}\n",
    "# for i in range(len(metrics)):\n",
    "#     data_pivot = pd.pivot_table(data, values=metrics[i], index=\"playDispNm\", columns = \"gmDate\")\n",
    "#     shifted_df = data_pivot.apply(lambda x: pd.Series(x.dropna().values), axis=1).fillna(np.nan)\n",
    "#     data_dict.update({metrics[i]: shifted_df})\n",
    "\n",
    "print(\"*** preparing data ***\")\n",
    "\n",
    "pred_date = pd.to_datetime('2012-12-01') # the year that we are living in\n",
    "pred_interval_time = pd.Timedelta(\"5 day\") # we are making predictions for pred_year+1 and +2\n",
    "\n",
    "\n",
    "########### Donor ##########\n",
    "# filter stats by the year\n",
    "donor_data = data[data.date <= pred_date]\n",
    "donor_dict = getDictionaryGameByGame(donor_data, metrics)\n",
    "donor = Donor(donor_dict)\n",
    "\n",
    "########### Target ##########\n",
    "# filter stats by the year\n",
    "target_data = data[data.date <= pred_date + pred_interval_time]\n",
    "target_dict = getDictionaryGameByGame(target_data, metrics)\n",
    "\n",
    "\"\"\" target \"\"\"\n",
    "data_pred = data[(data.date > pred_date)&(data.date <= pred_date+pred_interval_time)]\n",
    "# getDictionaryGameByGame(data_pred, ['playPTS'])['playPTS']\n",
    "allPlayers = list(data_pred.playDispNm.unique())\n",
    "allPlayers.sort()\n",
    "print(len(allPlayers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 metric at once\n",
      "(9, 461)\n",
      "*** MAPE ***\n",
      "playPTS     2.498844\n",
      "playAST     6.522290\n",
      "playTO      3.966629\n",
      "playFG%     2.373025\n",
      "playFT%     3.423726\n",
      "play3PM     1.932879\n",
      "playTRB     2.813439\n",
      "playSTL    11.543759\n",
      "playBLK     2.417315\n",
      "dtype: float64\n",
      "MAPE for all:  4.302826660025696\n",
      "\n",
      "*** RMSE ***\n",
      "playPTS    33.532858\n",
      "playAST    69.567546\n",
      "playTO     12.630808\n",
      "playFG%     3.431900\n",
      "playFT%     5.919400\n",
      "play3PM     4.900528\n",
      "playTRB    24.776438\n",
      "playSTL    45.193649\n",
      "playBLK     3.999013\n",
      "dtype: float64\n",
      "RMSE for all:  22.66134902876346\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "experiment setup\n",
    "\"\"\"\n",
    "# overall setup\n",
    "donorSetup= [None,\"sliding\", True]\n",
    "denoiseSetup = [\"SVD\", \"all\"]\n",
    "regression_method = \"pinv\"\n",
    "\n",
    "threshold = 0.97\n",
    "verbose = False\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "metrics_list = [[x] for x in metrics]\n",
    "\n",
    "\"\"\"\n",
    "experiment\n",
    "\"\"\"\n",
    "print(\"1 metric at once\")\n",
    "\n",
    "all_pred = pd.DataFrame()\n",
    "all_true = pd.DataFrame()\n",
    "for playerName in allPlayers:\n",
    "    # print(playerName)\n",
    "    # print(\"*** year - year_count matching for this player\")\n",
    "    # a = df_year[df_year.index == playerName]\n",
    "    # print(a.dropna(axis=1))\n",
    "\n",
    "    target = Target(playerName, target_dict)\n",
    "    # print(\"*** target - total index: \", target.total_index)\n",
    "    # print(target.concat(metrics_list[1]))\n",
    "\n",
    "    interv_index = donor_data[donor_data.playDispNm == playerName].shape[0]\n",
    "    pred_interval = target.total_index - interv_index\n",
    "    mrsc = mRSC(donor, target, pred_interval, probObservation=1)\n",
    "    \n",
    "    if (donor.concat([metrics[0]], target.total_index, method = \"sliding\").shape[0] <5):\n",
    "        continue\n",
    "        \n",
    "    player_pred = pd.DataFrame()\n",
    "    player_true = pd.DataFrame()\n",
    "    for i in range(len(metrics_list)):\n",
    "        mrsc.fit_threshold(metrics_list[i], threshold, donorSetup, denoiseSetup,regression_method, verbose)\n",
    "        pred = mrsc.predict()\n",
    "        true = mrsc.getTrue()\n",
    "        pred.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "        true.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "        player_pred = pd.concat([player_pred, pred], axis=0)\n",
    "        player_true = pd.concat([player_true, true], axis=0)\n",
    "    all_pred = pd.concat([all_pred, player_pred], axis=1)\n",
    "    all_true = pd.concat([all_true, player_true], axis=1)\n",
    "\n",
    "###################\n",
    "# print(all_pred)\n",
    "print(all_pred.shape)\n",
    "mask = (all_true !=0 )\n",
    "mape = np.abs(all_pred - all_true) / all_true[mask]\n",
    "print(\"*** MAPE ***\")\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "\n",
    "rmse = utils.rmse_2d(all_true, all_pred)\n",
    "print()\n",
    "print(\"*** RMSE ***\")\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** importing data ***\n",
      "*** preparing data ***\n",
      "\n",
      "targte columns\n",
      "DatetimeIndex(['2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31',\n",
      "               '2013-02-28', '2013-03-31', '2013-04-30', '2013-10-31',\n",
      "               '2013-11-30', '2013-12-31', '2014-01-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n",
      "donor columns\n",
      "DatetimeIndex(['2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31',\n",
      "               '2013-02-28', '2013-03-31', '2013-04-30', '2013-10-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import data\n",
    "\"\"\"\n",
    "print(\"*** importing data ***\")\n",
    "data = pd.read_csv(\"../data/nba-enhanced-stats/2012-18_playerBoxScore.csv\")\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "\n",
    "date_col = pd.to_datetime(data.gmDate + \" \" + data.gmTime, format='%Y-%m-%d %H:%M').rename(\"date\")\n",
    "data = pd.concat([date_col,data], axis=1)\n",
    "\n",
    "print(\"*** preparing data ***\")\n",
    "\n",
    "pred_date = pd.to_datetime('2013-10-31') # the year that we are living in\n",
    "pred_interval = 3\n",
    "pred_interval_time = pd.Timedelta(\"30 days\") * pred_interval # we are making predictions for pred_year+1 and +2\n",
    "\n",
    "\n",
    "########### Donor ##########\n",
    "# filter stats by the year\n",
    "donor_data = data[data.date <= pred_date]\n",
    "donor_dict, cols_donor = getMonthlyData(donor_data, metrics)\n",
    "donor = Donor(donor_dict)\n",
    "\n",
    "########### Target ##########\n",
    "# filter stats by the year\n",
    "target_data = data[data.date <= pred_date + pred_interval_time]\n",
    "target_dict, cols_target = getMonthlyData(target_data, metrics)\n",
    "\n",
    "print()\n",
    "print(\"targte columns\")\n",
    "print(cols_target)\n",
    "print(\"donor columns\")\n",
    "print(cols_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 metric at once\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Donor pool size too small. Donor pool size: Gustavo Ayon(0, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4325f4692cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mplayer_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonorSetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoiseSetup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/mrsc/src/synthcontrol/mRSC.py\u001b[0m in \u001b[0;36mfit_threshold\u001b[0;34m(self, metrics, threshold, donorSetup, denoiseSetup, regression_method, verbose)\u001b[0m\n\u001b[1;32m    165\u001b[0m                                   \u001b[0;32mand\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mNaN\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assignData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_form_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipNan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# compute approximate rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/mrsc/src/synthcontrol/mRSC.py\u001b[0m in \u001b[0;36m_assignData\u001b[0;34m(self, metrics, weighting, mat_form_method, skipNan)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdonor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Donor pool size too small. Donor pool size: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdonor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighting\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Donor pool size too small. Donor pool size: Gustavo Ayon(0, 9)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "experiment setup\n",
    "\"\"\"\n",
    "# overall setup\n",
    "donorSetup= [None,\"sliding\", True]\n",
    "denoiseSetup = [\"SVD\", \"all\"]\n",
    "regression_method = \"pinv\"\n",
    "\n",
    "threshold = 0.97\n",
    "verbose = False\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "metrics_list = [[x] for x in metrics]\n",
    "\n",
    "\"\"\"\n",
    "experiment\n",
    "\"\"\"\n",
    "print(\"1 metric at once\")\n",
    "\n",
    "all_pred = pd.DataFrame()\n",
    "all_true = pd.DataFrame()\n",
    "# for playerName in playerNames:\n",
    "playerName = allPlayers[123]\n",
    "# print(playerName)\n",
    "# print(\"*** year - year_count matching for this player\")\n",
    "# a = df_year[df_year.index == playerName]\n",
    "# print(a.dropna(axis=1))\n",
    "\n",
    "target = Target(playerName, target_dict)\n",
    "# print(\"*** target - total index: \", target.total_index)\n",
    "# print(target.concat(metrics_list[1]))\n",
    "\n",
    "interv_index = donor_data[donor_data.playDispNm == playerName].shape[0]\n",
    "pred_interval = target.total_index - interv_index\n",
    "mrsc = mRSC(donor, target, pred_interval, probObservation=1)\n",
    "\n",
    "# if (donor.concat([metrics[0]], target.total_index, method = \"sliding\").shape[0] <5):\n",
    "#     continue\n",
    "\n",
    "player_pred = pd.DataFrame()\n",
    "player_true = pd.DataFrame()\n",
    "for i in range(len(metrics_list)):\n",
    "    mrsc.fit_threshold(metrics_list[i], threshold, donorSetup, denoiseSetup,regression_method, verbose)\n",
    "    pred = mrsc.predict()\n",
    "    true = mrsc.getTrue()\n",
    "    pred.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "    true.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "    player_pred = pd.concat([player_pred, pred], axis=0)\n",
    "    player_true = pd.concat([player_true, true], axis=0)\n",
    "all_pred = pd.concat([all_pred, player_pred], axis=1)\n",
    "all_true = pd.concat([all_true, player_true], axis=1)\n",
    "\n",
    "###################\n",
    "# print(all_pred)\n",
    "print(all_pred.shape)\n",
    "mask = (all_true !=0 )\n",
    "mape = np.abs(all_pred - all_true) / all_true[mask]\n",
    "print(\"*** MAPE ***\")\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "\n",
    "rmse = utils.rmse_2d(all_true, all_pred)\n",
    "print()\n",
    "print(\"*** RMSE ***\")\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: outputs the mean of the player's history\n",
      "-----\n",
      "*** MAPE ***\n",
      "PTS_G    0.413246\n",
      "AST_G    0.387396\n",
      "TOV_G    0.400230\n",
      "TRB_G    0.275911\n",
      "STL_G    0.320220\n",
      "BLK_G    0.454082\n",
      "3P_G     0.533344\n",
      "FG%      0.063127\n",
      "FT%      0.061047\n",
      "PER_w    0.202120\n",
      "dtype: float64\n",
      "MAPE for all:  0.306121947982417\n",
      "\n",
      "*** RMSE ***\n",
      "PTS_G    4.409235\n",
      "AST_G    1.131206\n",
      "TOV_G    0.564801\n",
      "TRB_G    1.450656\n",
      "STL_G    0.274086\n",
      "BLK_G    0.235605\n",
      "3P_G     0.466516\n",
      "FG%      0.036495\n",
      "FT%      0.057969\n",
      "PER_w    3.312910\n",
      "dtype: float64\n",
      "RMSE for all:  1.1939480121133492\n"
     ]
    }
   ],
   "source": [
    "# metrics_to_use= [\"PTS_G\",\"AST_G\",\"TOV_G\",\"PER_w\", \"FG%\",\"FT%\",\"3P_G\",\"TRB_G\",\"STL_G\",\"BLK_G\"]\n",
    "metrics_to_use = allMetrics\n",
    "\n",
    "print(\"Algo: outputs the mean of the player's history\")\n",
    "print(\"-----\")\n",
    "pred_all = pd.DataFrame()\n",
    "true_all = pd.DataFrame()\n",
    "for playerName in playerNames:\n",
    "    target = Target(playerName, allPivotedTableDict)\n",
    "    true, pred = getBenchmark(target, metrics_to_use, pred_interval)\n",
    "    \n",
    "    pred_all = pd.concat([pred_all, pred], axis=1)\n",
    "    true_all = pd.concat([true_all, true], axis=1)\n",
    "\n",
    "###################\n",
    "mask = (true_all !=0 )\n",
    "mape = np.abs(pred_all - true_all) / true_all[mask]\n",
    "print(\"*** MAPE ***\")\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "\n",
    "rmse = utils.rmse_2d(true_all, pred_all)\n",
    "print()\n",
    "print(\"*** RMSE ***\")\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PTS_G\n",
      "Tyler Hansbrough 0    2.60442\n",
      "Kirk Hinrich 0        2.54157\n",
      "Nick Collison 0       2.40373\n",
      "Tayshaun Prince 0     1.82742\n",
      "Ty Lawson 0           1.48293\n",
      "Jason Thompson 0      1.42104\n",
      "Brandon Jennings 0    1.19949\n",
      "Steve Blake 0         1.19918\n",
      "Jonas Jerebko 0       1.19298\n",
      "Beno Udrih 0          1.15311\n",
      "Name: PTS_G, dtype: object\n",
      "\n",
      "AST_G\n",
      "Anthony Morrow 0       7.07181\n",
      "Tyler Hansbrough 0     5.93413\n",
      "Nick Young 0            3.7168\n",
      "Bismack Biyombo 0      3.34997\n",
      "Wesley Johnson 0       2.60229\n",
      "DeAndre Jordan 0       2.04812\n",
      "Enes Kanter 0          2.00037\n",
      "Richard Jefferson 0    1.92116\n",
      "C.J. Miles 0           1.85656\n",
      "Anthony Tolliver 0     1.66044\n",
      "Name: AST_G, dtype: object\n",
      "\n",
      "TOV_G\n",
      "Anthony Morrow 0       5.14906\n",
      "Tyler Hansbrough 0     3.34793\n",
      "Anthony Tolliver 0     2.25923\n",
      "Jason Thompson 0       2.25143\n",
      "Tayshaun Prince 0      2.21373\n",
      "Nick Young 0           1.68462\n",
      "Kirk Hinrich 0         1.34559\n",
      "Wayne Ellington 0      1.31643\n",
      "Richard Jefferson 0    1.18031\n",
      "Gary Neal 0            1.16256\n",
      "Name: TOV_G, dtype: object\n",
      "\n",
      "TRB_G\n",
      "Anthony Morrow 0       3.70143\n",
      "Tyler Hansbrough 0     1.61108\n",
      "Richard Jefferson 0    1.41866\n",
      "James Johnson 0         1.3922\n",
      "Beno Udrih 0           1.30666\n",
      "Tayshaun Prince 0      1.25132\n",
      "Marco Belinelli 0      1.22606\n",
      "Kevin Seraphin 0        1.2194\n",
      "Shaun Livingston 0     1.18057\n",
      "Vince Carter 0         1.07918\n",
      "Name: TRB_G, dtype: object\n",
      "\n",
      "STL_G\n",
      "Kevin Seraphin 0         2.117\n",
      "Robin Lopez 0          1.79735\n",
      "Jonas Jerebko 0        1.74216\n",
      "Anthony Morrow 0       1.64995\n",
      "Mo Williams 0          1.58419\n",
      "Kirk Hinrich 0         1.44119\n",
      "Beno Udrih 0           1.39448\n",
      "Marreese Speights 0    1.37434\n",
      "J.J. Barea 0            1.3637\n",
      "Arron Afflalo 0        1.29076\n",
      "Name: STL_G, dtype: object\n",
      "\n",
      "BLK_G\n",
      "Gary Neal 0           13.7748\n",
      "Beno Udrih 0          13.6342\n",
      "Marco Belinelli 0     10.6879\n",
      "J.J. Barea 0          10.0785\n",
      "Wayne Ellington 0     5.87194\n",
      "Anthony Morrow 0      4.66112\n",
      "Ramon Sessions 0      4.27348\n",
      "Derrick Williams 0    4.16758\n",
      "Marcus Thornton 0     4.03155\n",
      "Darren Collison 0     4.02565\n",
      "Name: BLK_G, dtype: object\n",
      "\n",
      "3P_G\n",
      "Shaun Livingston 0    19.4472\n",
      "Dwyane Wade 0         11.1854\n",
      "David West 0          10.4453\n",
      "Tayshaun Prince 0     7.41258\n",
      "Marc Gasol 0          6.78693\n",
      "Nikola Vucevic 0      5.66283\n",
      "Kenneth Faried 0      4.65928\n",
      "Thaddeus Young 0      4.36624\n",
      "Timofey Mozgov 0      4.10471\n",
      "Tyler Hansbrough 0    3.37578\n",
      "Name: 3P_G, dtype: object\n",
      "\n",
      "FG%\n",
      "Josh Smith 0           0.21915\n",
      "Ian Mahinmi 0         0.208157\n",
      "DeAndre Jordan 0      0.205159\n",
      "Paul Pierce 0         0.203027\n",
      "Nick Young 0          0.195301\n",
      "Thabo Sefolosha 0      0.19429\n",
      "Lance Stephenson 0      0.1887\n",
      "Tristan Thompson 0    0.187127\n",
      "Boris Diaw 0          0.186375\n",
      "Shaun Livingston 0    0.175766\n",
      "Name: FG%, dtype: object\n",
      "\n",
      "FT%\n",
      "DeAndre Jordan 0     0.553534\n",
      "Dwight Howard 0      0.525601\n",
      "Josh Smith 0         0.271946\n",
      "LeBron James 0       0.270228\n",
      "Amir Johnson 0       0.261706\n",
      "Andre Iguodala 0     0.258114\n",
      "Kenneth Faried 0     0.248167\n",
      "Kris Humphries 0     0.215947\n",
      "Ed Davis 0           0.213194\n",
      "Wayne Ellington 0    0.213069\n",
      "Name: FT%, dtype: object\n",
      "\n",
      "PER_w\n",
      "Tayshaun Prince 0     1.02083\n",
      "O.J. Mayo 0          0.912802\n",
      "Kirk Hinrich 0       0.884641\n",
      "Randy Foye 0         0.814417\n",
      "Ty Lawson 0          0.738239\n",
      "Paul Pierce 0        0.715094\n",
      "Nick Collison 0      0.678532\n",
      "Iman Shumpert 0      0.609869\n",
      "Nick Young 0         0.501974\n",
      "Marco Belinelli 0    0.456315\n",
      "Name: PER_w, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for metric in allMetrics:\n",
    "    print()\n",
    "    print(metric)\n",
    "    print(mape.loc[metric,:].sort_values(ascending = False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 99)\n",
      "*** MAPE ***\n",
      "PTS_G    0.274777\n",
      "AST_G    0.537414\n",
      "TOV_G    0.309435\n",
      "TRB_G    0.181637\n",
      "STL_G    0.231816\n",
      "BLK_G    0.374646\n",
      "3P_G     1.778391\n",
      "FG%      0.071516\n",
      "FT%      0.099925\n",
      "PER_w    0.190299\n",
      "dtype: float64\n",
      "MAPE for all:  0.38260637091850613\n",
      "\n",
      "*** RMSE ***\n",
      "PTS_G    5.052958\n",
      "AST_G    1.798591\n",
      "TOV_G    0.700045\n",
      "TRB_G    1.167430\n",
      "STL_G    0.234047\n",
      "BLK_G    0.190006\n",
      "3P_G     0.780453\n",
      "FG%      0.051968\n",
      "FT%      0.093497\n",
      "PER_w    4.362244\n",
      "dtype: float64\n",
      "RMSE for all:  1.4431239627611094\n",
      "\n",
      "*** R2 ***\n",
      "PTS_G    -65.290399\n",
      "AST_G   -178.406691\n",
      "TOV_G    -68.639120\n",
      "TRB_G      0.755287\n",
      "STL_G      0.998910\n",
      "BLK_G     -6.225443\n",
      "3P_G    -116.758836\n",
      "FG%        0.999972\n",
      "FT%      -24.373353\n",
      "PER_w     -3.446957\n",
      "dtype: float64\n",
      "R2 for all:  -46.03866302248279\n"
     ]
    }
   ],
   "source": [
    "print(all_pred.shape)\n",
    "mask = (all_true !=0 )\n",
    "mape = np.abs(all_pred - all_true) / all_true[mask]\n",
    "print(\"*** MAPE ***\")\n",
    "print(mape.mean(axis=1).reindex(allMetrics))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "\n",
    "rmse = utils.rmse_2d(all_true, all_pred)\n",
    "print()\n",
    "print(\"*** RMSE ***\")\n",
    "print(rmse.reindex(allMetrics))\n",
    "print(\"RMSE for all: \", rmse.mean())\n",
    "\n",
    "print()\n",
    "print(\"*** R2 ***\")\n",
    "print(all_R2.mean(axis=1).reindex(allMetrics))\n",
    "print(\"R2 for all: \", all_R2.mean(axis=1).mean(axis=0))\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonthlyData(data, metrics):\n",
    "    df = copy.deepcopy(data)\n",
    "    df.index = df.date\n",
    "    df_grouped = df.groupby(by =[df.playDispNm,pd.Grouper(freq='M')]).mean()\n",
    "    \n",
    "    my_dict = {}\n",
    "    for i in range(len(metrics)):\n",
    "        df_pivoted = pd.pivot_table(df_grouped, values = 'playPTS', index='playDispNm', columns=\"date\")\n",
    "        cols = df_pivoted.columns\n",
    "        df_pivoted.columns = range(df_pivoted.shape[1])\n",
    "        my_dict.update({metrics[i]: df_pivoted})\n",
    "    return my_dict, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** importing data ***\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import data\n",
    "\"\"\"\n",
    "print(\"*** importing data ***\")\n",
    "data = pd.read_csv(\"../data/nba-enhanced-stats/2012-18_playerBoxScore.csv\")\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "\n",
    "date_col = pd.to_datetime(data.gmDate + \" \" + data.gmTime, format='%Y-%m-%d %H:%M').rename(\"date\")\n",
    "data = pd.concat([date_col,data], axis=1)\n",
    "\n",
    "print(\"*** preparing data ***\")\n",
    "\n",
    "pred_date = pd.to_datetime('2013-10-31') # the year that we are living in\n",
    "pred_interval = 3\n",
    "pred_interval_time = pd.Timedelta(\"30 days\") * pred_interval # we are making predictions for pred_year+1 and +2\n",
    "\n",
    "\n",
    "########### Donor ##########\n",
    "# filter stats by the year\n",
    "donor_data = data[data.date <= pred_date]\n",
    "donor_dict, cols_donor = getMonthlyData(donor_data, metrics)\n",
    "donor = Donor(donor_dict)\n",
    "\n",
    "########### Target ##########\n",
    "# filter stats by the year\n",
    "target_data = data[data.date <= pred_date + pred_interval_time]\n",
    "target_dict, cols_target = getMonthlyData(target_data, metrics)\n",
    "\n",
    "print()\n",
    "print(\"targte columns\")\n",
    "print(cols_target)\n",
    "print(\"donor columns\")\n",
    "print(cols_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** preparing data ***\n",
      "\n",
      "targte columns\n",
      "DatetimeIndex(['2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31',\n",
      "               '2013-02-28', '2013-03-31', '2013-04-30', '2013-10-31',\n",
      "               '2013-11-30', '2013-12-31', '2014-01-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n",
      "donor columns\n",
      "DatetimeIndex(['2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31',\n",
      "               '2013-02-28', '2013-03-31', '2013-04-30', '2013-10-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    }
   ],
   "source": [
    "\"\"\" target \"\"\"\n",
    "data_pred = data[(data.date > pred_date)&(data.date <= pred_date+pred_interval_time)]\n",
    "# getDictionaryGameByGame(data_pred, ['playPTS'])['playPTS']\n",
    "allPlayers = list(data_pred.playDispNm.unique())\n",
    "allPlayers.sort()\n",
    "print(len(allPlayers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((target_dict['playPTS'].index).isin(playerNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 metric at once\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Donor pool size too small. Donor pool size: Tony Allen(0, 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a029c2a92590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mplayer_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonorSetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoiseSetup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/mrsc/src/synthcontrol/mRSC.py\u001b[0m in \u001b[0;36mfit_threshold\u001b[0;34m(self, metrics, threshold, donorSetup, denoiseSetup, regression_method, verbose)\u001b[0m\n\u001b[1;32m    165\u001b[0m                                   \u001b[0;32mand\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mNaN\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assignData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_form_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipNan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# compute approximate rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/mrsc/src/synthcontrol/mRSC.py\u001b[0m in \u001b[0;36m_assignData\u001b[0;34m(self, metrics, weighting, mat_form_method, skipNan)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdonor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Donor pool size too small. Donor pool size: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdonor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighting\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Donor pool size too small. Donor pool size: Tony Allen(0, 11)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "experiment setup\n",
    "\"\"\"\n",
    "# overall setup\n",
    "donorSetup= [None,\"sliding\", True]\n",
    "denoiseSetup = [\"SVD\", \"all\"]\n",
    "regression_method = \"pinv\"\n",
    "\n",
    "threshold = 0.97\n",
    "verbose = False\n",
    "\n",
    "metrics = ['playPTS', 'playAST', 'playTO','playFG%','playFT%','play3PM','playTRB','playSTL', 'playBLK']\n",
    "metrics_list = [[x] for x in metrics]\n",
    "\n",
    "\"\"\"\n",
    "experiment\n",
    "\"\"\"\n",
    "print(\"1 metric at once\")\n",
    "\n",
    "all_pred = pd.DataFrame()\n",
    "all_true = pd.DataFrame()\n",
    "# for playerName in playerNames:\n",
    "playerName = playerNames[0]\n",
    "# print(playerName)\n",
    "# print(\"*** year - year_count matching for this player\")\n",
    "# a = df_year[df_year.index == playerName]\n",
    "# print(a.dropna(axis=1))\n",
    "\n",
    "target = Target(playerName, target_dict)\n",
    "# print(\"*** target - total index: \", target.total_index)\n",
    "# print(target.concat(metrics_list[1]))\n",
    "\n",
    "interv_index = donor_data[donor_data.playDispNm == playerName].shape[0]\n",
    "pred_interval = target.total_index - interv_index\n",
    "mrsc = mRSC(donor, target, pred_interval, probObservation=1)\n",
    "\n",
    "# if (donor.concat([metrics[0]], target.total_index, method = \"sliding\").shape[0] <5):\n",
    "#     continue\n",
    "\n",
    "player_pred = pd.DataFrame()\n",
    "player_true = pd.DataFrame()\n",
    "for i in range(len(metrics_list)):\n",
    "    mrsc.fit_threshold(metrics_list[i], threshold, donorSetup, denoiseSetup,regression_method, verbose)\n",
    "    pred = mrsc.predict()\n",
    "    true = mrsc.getTrue()\n",
    "    pred.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "    true.columns = [playerName +\" \"+ str(a) for a in range(pred_interval)]\n",
    "    player_pred = pd.concat([player_pred, pred], axis=0)\n",
    "    player_true = pd.concat([player_true, true], axis=0)\n",
    "all_pred = pd.concat([all_pred, player_pred], axis=1)\n",
    "all_true = pd.concat([all_true, player_true], axis=1)\n",
    "\n",
    "###################\n",
    "# print(all_pred)\n",
    "print(all_pred.shape)\n",
    "mask = (all_true !=0 )\n",
    "mape = np.abs(all_pred - all_true) / all_true[mask]\n",
    "print(\"*** MAPE ***\")\n",
    "print(mape.mean(axis=1))\n",
    "print(\"MAPE for all: \", mape.mean().mean())\n",
    "\n",
    "rmse = utils.rmse_2d(all_true, all_pred)\n",
    "print()\n",
    "print(\"*** RMSE ***\")\n",
    "print(rmse)\n",
    "print(\"RMSE for all: \", rmse.mean())\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
